# Machine Learning

</br>

## Overfitting(과적합)과 Generalization

</br>

### 새로운 데이터들에 대해서도 좋은 결과를 내게 하려면?

* **Cross Validation (교차 검증)**

  * 데이터를 3개의 그룹으로 나눈다.
    1) 60%의 Training data로 모델을 학습 (Learn) 시킨다.
    2) 20%의 Validation data로 모델(or Hyper Parameter)을 최적화 / 선택(Tune)한다.
    3) 20%의 Test data로 모델을 평가 (Test only, no more tune)한다.
  * Validation & Test의 차이
    * Validation : 여러 후보 모델 중 가장 좋은 결과를 내는 모델을 선택하는 과정
    * Test : 선택한 모델의 실제 정확도를 평가하는 것 (Estimate the accuracy)
    * 여러 모델 or Hyper params 중 선택을 해야하는 경우가 아니라면 Validation과 Test를 나누지 않고 진행하기도 함

  * 무조건 6 : 2 : 2 or 7 : 3 ?

    * 100 ~ n * 10,000 data   ->   **6 : 2 : 2 or 7 : 3**

    * more than n * 100,000 data  ->  **98 : 1 : 1**  or  99 : 0.5 : 0.5 ...

      </br>

* 그 외 활용되는 방법들

  * **K - Fold** cross Validation (후보 모델 간 비교 및 선택을 위한 알고리즘)
  * Cost function에 Regularization term 추가 (딥러닝 기법)  (L1 or L2, weight up = cost up)
  * Drop - out & Batch Normalization 등  (딥러닝 기법)
  * **Training data를 많이 확보하거나 모델의  Feature를 줄이는 것도 좋은 방법  (+ Data augmentation (데이터 뻥튀기 기술) & Test time augmentation)**
  * 딥러닝에서 클래스 불균형을 다루는 방법
    * Weight balancing & Focal loss
    * Over & under sampling
    * SMOTE

  </br>

* (Stratified / 층화 ) **K-Fold** Cross Validation

  * K (사람이 결정해주는 것)  -> 보통 5 아님 10으로 줌

    ex) 10 Fold Cross Validation

  * **다수의 모델이 있을 때, 어떤 모델이 가장 괜찮은지 판단하고 싶을 때 씀**

  * K-Fold Cross Validation 원리

    ![](C:\Users\kanga\gitProjects\Machine Learning study\K-Fold .jpg)

